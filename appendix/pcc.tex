\chapter[Reproducible Computational Infrastructure]{Reproducible Computational Infrastructure%
  \protect\footnotemark[1]% idk
}
\footnotetext{The code described in this chapter is referenced under DOI 10.5281/zenodo.45950}
\label{ch:pcc}

\section{Introduction}


There has been much attention recently paid to reproducible computational research \cite{Stodden2013}.
%
In some cases, just providing the computational code and data, along with some instructions, is sufficient to be able to reproduce a computational experiment.
%
However, typically code relies on libraries and other support facilities which complicates the computational setup.
%
So, just providing the computational code is not sufficient to ensure reproducibility (at least not easily).
%
Some domains have managed this complexity somewhat by providing specific solutions.
%
As examples, \textsf{Galaxy} is used in genome analysis \cite{Giardine2005},
%
\textsf{Madagascar} in geophysics \cite{Fomel2013},
%
\textsf{WaveLab} in signal processing \cite{Buckheit1995},
%
and \textsf{Bioconductor} in computational biology and bioinformatics \cite{Gentleman2004}.
%
These solutions can be seen as platforms onto which instructions can be provided to reproduce results.


However, these solutions do not address computational infrastructure setup in addition to being limited to their domains.
%
`Infrastructure' here means aspects related to both hardware and software.
%
While the importance of hardware is not emphasized as much as software in reproducibility%
\footnote{This is because the quantitative programmer is usually highly removed from hardware details. The same cannot be said of software dependencies.}%
,
it is best to think of hardware as clean slates onto which software is installed, beginning with the operating system.
%
In fact, some computational code requires certain hardware like graphics processing units (GPUs).
%
Furthermore, computational codes might interact with (non-computational) services provided by the operating system and/or non-computational services that perhaps are closely associated with the operating system.
%
Therefore providing instructions, in the form of code, that specify the hardware \emph{and} software has much value for reproducibility.
%
The benefit from having such instructions is not limited to ensuring integrity of results;
%
the iterative work process is greatly enhanced because this level of reproducibility implies automation.


Many software tools from information technology (not specific to high-performance computing) automate infrastructure setup.
%
As such, the results presented in Chapter \ref{ch:results}, were obtained by using an automated process that used some of these information technology tools.
%
Furthermore, while being motivated by a problem encountered in this work, the process has been separated out as an independent solution applicable to any computational problem.


The following sections describe the problem and, in turn, its solution.


\subsection{Motivation}
\label{sec:pccmotivation}

The Bayesian optimization process, explained in Section \ref{sec:training}, requires the coordination of many components.
%
The general problem is explained here but refer to Chapter \ref{ch:reproduce} for the specific solution components.
%
The components must satisfy the following requirements:
%
\begin{itemize}

\item 
  the provisioning of a \textsf{MongoDB} database so that \textsf{Spearmint} could store its optimization progress in it

\item
  the provisioning of a database to store RNN parameters after every training iteration

\item
  the coordination of training runs on potentially multiple compute machines where a RNN training run is for certain hyper-parameters (a coarse form of parallelization)

\end{itemize}

Furthermore, two operational requirements can be added as well:

\begin{itemize}

\item
  There should be an automated (reproducible) process that sets up these components.

\item
  The investigator should be able to seamlessly transition from testing and development on his/her local machine to `production' execution on a remote machine.
%
That is, the investigator's workflow should be uninterrupted.

\end{itemize}


So the challenge is twofold: the reproducibility of each component and the reproducibility of the setup.
%
This implies that the setup should occur in clean, isolated environments.


\section{Solution Elements}


Some solutions solve certain parts of the previously listed requirements.
%
They can be evaluated based on their degree of reproducibility and automation.


\begin{description}


\item[local virtual machine: \textsf{VirtualBox}.]
  %
  This software virtualizes all the workings of a machine into a process running on a (local) host operating system.

  
  However, on its own, \textsf{VirtualBox} does not provide a systematic and generic way of provisioning the machine as well as provisioning software on the machine.


\item[local virtual machine automation: \textsf{Vagrant}.]
  %
  By providing \textsf{Vagrant} with instructions in a file, virtual machine setup can be automated.
  

  \textsf{Vagrant} can control \textsf{VirtualBox} by specifying virtual machine hardware as well a machine image (file) which typically includes an operating system installation at least.
  %
  While a virtual machine provisioned automatically provides an isolated, reproducible environment for work, it needs to exist in the context of being a part of a network of machines.
  %
  So, ideally, after a minimal initial provisioning, the virtual machine should be treated as just another machine regardless of the fact that it exists virtualized locally.


\item[application reproducibility: \textsf{Docker}.]
  %
  From instructions in a file, \textsf{Docker} can create an isolated application image.


  \textsf{Docker} has recently emerged as an easy yet powerful way to work with (isolated) application containers.
  %
  Furthermore, the image execution is portable as long as the machine has compatible hardware architecture which has obvious advantages when working with multiple machines.
  %
  Also, by persisting the image, the application can be started swiftly since the image is the result of potentially lengthy software installation processes.
  %
%footnote? docker like vm but compare to handling vm img!
  %
%used for svc and the compute code as well.
%
  In the context of computational research, it is possible to have isolated, reproducible containers for, as examples, databases, computational code, and computational task management.
  %
  While \textsf{Docker} provides a great deal of application reproducibility, it is not involved in machine provisioning.



\item[distributed \textsf{Docker} support: \textsf{Weave} and \textsf{CoreOS}.]
%
\textsf{Weave} and \textsf{CoreOS} facilitate the distributed operation of \textsf{Docker} containers.

Given that \textsf{Docker} was identified as an important solution component, it follows that \textsf{Docker}-specific solutions should be chosen that facilitate distributed application execution.
%
\textsf{Weave} provides global private network addressing for each container.
%
\textsf{CoreOS} is a \textsf{Linux} operating system designed for distributed, containerized applications.
%
As such, it is delivered with minimal software and services as containers are assumed to be the primary method by which software and services are added.
%
In the context of computational research, this ensures the fastest possible execution of computational code since the operating system is not running unnecessary processes.
%docker soles other probs but these are main ones


\item[remote machine facility: \textsf{Amazon Web Services (AWS)}.] 
  %
  \textsf{AWS} provides high-\\performance compute machines, including machines equipped with GPUs, running \textsf{CoreOS}.
  

  What is important for the purpose of automation is that \textsf{AWS} provides a programmatic interface for the provisioning of machines.
  % 
  However, the choice of \textsf{AWS} is not critical because \textsf{AWS} can be substituted by other providers with comparable facilities.
 


\item[global automation: \textsf{Ansible}.]
  %
  \textsf{Ansible} is the highest-level automation software that can orchestrate the infrastructure setup process (in full).
  
  \textsf{Ansible} can be used to generically provision machines, local or remote, virtual or physical.
  %
  \textsf{Ansible} can also be used to provision software, containerized or not.
  %
  Furthermore, the provisioning of hardware and software can occur in a coordinated fashion.

% use ansible to coordinate this. other coordiantion tools exist but ansible is a good base generic. lot's of support. customized for this workflow.


\end{description}


\subsection{Solution Stack}
\label{sec:stack}


The solution elements can be organized into a `stack' to help understand their place in an overall solution.
%
As depicted in Table \ref{tbl:stack}, the stack represents a technology dependency where higher elements depend on lower elements.
%
The goal is to be able to automatically recreate this technology stack anywhere.
%
As such, \textsf{Ansible} is not shown because it is an automation tool that sets up the stack.


\begin{table}[h]
\newcolumntype{T}{!{\color{blue} \vrule width 4\arrayrulewidth}}
\newcolumntype{C}[0]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{1.5in}}
\centering
\caption[Container-oriented computational technology stack]
{Container-oriented computational technology stack.
%
Technologies in shaded cells are under the influence of automation by \textsf{Ansible}.
%
The parentheses around x64 indicate that the hardware architecture is virtualized (under type-2 hypervisor).
%
Table cells containing ellipses are immaterial to the discussion.
%
}
\begin{tabular}{l C C}
  \Xhline{6\arrayrulewidth}
  application   
  &  \multicolumn{1}{TcT}{\cellcolor{blue!10}\ldots}
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}\ldots} 
  \\
  \hline
  container network 
  & \multicolumn{2}{TcT}{\cellcolor{blue!10}\textsf{Weave}}  
  \\
  app. containerization  
  & \multicolumn{2}{TcT}{\cellcolor{blue!10}\textsf{Docker}}   
  \\
  \hline
  operating system 
  & \multicolumn{2}{TcT}{\cellcolor{blue!10}\textsf{CoreOS}} 
  \\ 
  \hline
  machine 
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}(x64)}
  &  \multicolumn{1}{TcT}{\cellcolor{blue!10}x64} 
  \\ 
  \hline
  hypervisor 
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}\textsf{VirtualBox}} 
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}\ldots }
  \\
  hypervisor interface
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}\textsf{Vagrant}} 
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}\textsf{AWS}}
  \\
  \hline
  host operating sys. 
  & \multicolumn{1}{|c|}{
    \textsf{Windows}%
    \textbar \textsf{OS X}%
    \textbar \textsf{Linux}
    }
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}\ldots}
  \\
  \hline
  hardware 
  & \multicolumn{1}{|c|}{x64}
  & \multicolumn{1}{TcT}{\cellcolor{blue!10}x64}
  \\
  \Xhline{6\arrayrulewidth}
  & local 
  & remote
\end{tabular}
\label{tbl:stack}
\end{table}


The reproducibility of results from computation (at the application layer) is generally not influenced by technologies lower in the stack.
%
In fact, they can be swapped with other technologies as long as the technology stack is compatible.
%
But the automation ensures the compatibility of the stack.


For reproduciblity of results, it is more a matter of convenience that the layers above the hypervisor can be recreated locally and remotely.
%
However, the technologies selected facilitate portability of execution in several ways which allows for easier collaboration and reproducibility of results starting at different levels.
%
At the lowest level, the automation code can recreate the full stack, locally and remotely, perhaps with different hypervisors.
%
So, at the container level, the highest level, \textsf{Docker} instructions can be used to recreate the application image.
%
Alternatively, the image (itself) can be transferred to any compatible machine for execution.
%
At the application level, only the most independent codes are truly portable.
%
Practically all modern computational codes have complex dependencies which are handled in a variety of ways.
%
But by using \textsf{Docker}, dependencies are handled in the most general way.


In fact, the level of encapsulation that \textsf{Docker} offers has  been compared to that of virtual machines (inaccurately%
\footnote{It is best to think of \textsf{Docker} containers as encapsulated \emph{processes}.}%
).
%
But unlike a virtual machine, it does not suffer from the additional overhead incurred by running an operating system and possibly virtualizing hardware as well.
%
In fact, the overhead of running \textsf{Docker} is negligible.
%
So if the concern is just running a typical application, transferring a \textsf{Docker} image is preferable to transferring a virtual machine image%
\footnote{
Applications requiring specialized hardware such as GPUs are not as transferable.
}%
.


But speaking of a `stack' on a machine, individually, does not address distributed computing.
%
Using multiple machines to accelerate computing is highly-desirable, if not essential, depending on the application.
%todo: is this sentence redundant?
%
This is where automating the entire stack on any compute provider, homogeneously, becomes advantageous since the automation code embodies the distributed environment.
%
Therefore, even the distributed environment can be reproducible.



\subsection{Partial Solutions}


Research-oriented cluster computing facilities were found to not satisfy the requirements previously mentioned.
%
Typically, the machines are provided with an operating system installed with a restricted user account.
%
This restricts the ease in which some software can be installed although this can be mitigated somewhat if \textsf{Docker} is installed.
%
Most importantly, is that the use of research-oriented clusters does not facilitate a seamless transition from local development to remote execution because the local and remote environments do not match (unless the local environment is restricted to use the same technologies as the facility which would limit portability of the setup process).
%
So treating cluster computing providers as just providers of machines is advantageous because it allows the investigator to generically automate the setup of the same computing environment on any facility.


While automating the setup on a research-oriented cluster is possible, \textsf{StarCluster} is notable for automating the setup on \textsf{AWS}.
%
Although the setup is convenient, \textsf{StarCluster} otherwise is much like a research-oriented cluster computing facility but with more control given to the user since administrative privileges on the operating systems are granted.
%
Not only is \textsf{StarCluster} restricted to \textsf{AWS}, but its technology stack is not designed for the primary usage of \textsf{Docker}.
%
Furthermore, the argument holds that \textsf{StarCluster} does not facilitate the seamless transition from local development to remote execution due to the mismatch between the environments.



\section{Solution}


Section \ref{sec:stack} discussed the advantages of having a homogeneous computing stack on any hardware based on \textsf{Docker} solutions.
%
This section will exhibit a `base' infrastructure onto which complex distributed applications can run.
%
The end result is that the investigator gains control of multiple machines all of which have almost identical environments.
%
Figure \ref{fig:pcc} depicts the base infrastructure in a technology layer-oriented view.
%layer view. not net view.
%
Machines occupying the top row in the diagram are designated as `compute' machines.

\begin{sidewaysfigure}[h]

  \includegraphics[width=\textwidth]{appendix/figs/arch.pdf}

\caption[Generic infrastructure for distributed computation based on \textsf{Docker}]{
Generic infrastructure for distributed computation based on \textsf{Docker}.
%
Dashed boxes group networks.
%
The (dotted) \textsf{Weave} network crosses network boundaries.
}
\label{fig:pcc}
\end{sidewaysfigure}


The general infrastructure setup procedure, controlled by \textsf{Ansible}, is as follows:

\begin{description}

\item[1. File Share Setup] \hfill 

The base infrastructure begins with setting up resources on a user's local machine to enable the execution of applications on remote machines.


Central to this is sharing local files which provides persistence of data and executables between instantiations of machines.
%
The file share also provides convenience for developing code on any machine which is especially powerful when using version controlled code.


\item[2. \texttt{init} Machine Setup] \hfill

  The purpose of the \texttt{init} machine is to provide coordination services and other low resource services to other machines in the network.
%
In the base setup the \texttt{init} machine provides two services:

  \begin{description}

    \item[File Share Expose] \hfill

      Through the use of \textsf{Weave}, the \texttt{init} machine sets up, transparently, local \emph{or} remote, access to the file share.

    \item[\textsf{Docker} registry] \hfill

      The \textsf{init} machine runs a \textsf{Docker} registry (of \textsf{Docker} images) so that any machine can download service and computation applications for execution.

      The images are built from code (in `\texttt{Dockerfiles}') in an initialization process.
      %
      The images can modularly build on one another.
      %
      For example, \textsf{app1} and \textsf{app2} (shown in Figure \ref{fig:pcc}) can build on a common \textsf{lib} image.

  \end{description}


\item[3. Compute Machine Provisioning] \hfill

After the \texttt{init} machine is set up, compute machines can be brought into the set of machines controlled by \textsf{Ansible}.
%
Local compute%
\footnote{
Non-virtualized local computing resources can be added to the network like \textsf{app3} running on \texttt{localhost} as shown in Figure \ref{fig:pcc}.
%
But such operation is not the purview of the automation code.
}
machines can be provisioned by \textsf{Vagrant} which are well-suited for testing.
%
Remote compute machines can be acquired as well from \textsf{AWS}%
\footnote{
Other providers can be integrated by creating and modifying \textsf{Ansible} scripts.
}
for accelerated execution.


\end{description}


After the setup, the investigator can expect that the same commands will work on any machine.
%
Moreover, the set up can be executed on any (local) machine.
%
This is demonstrated in Chapter \ref{ch:reproduce}.


More details on the setup and its use can be found in the code repository \url{https://github.com/majidaldo/personal-compute-cloud}.


%todo? note: with so many components it becomes v important to define s/w vers. at least since everything is code it beomces part of the process
%plus the computational code layers on top.

%\section{Advantages}


% benefits:
% code -> binary -> vm binary


% adv:
% - code is portable b/c it is agnostic to compute facility
% - reproducible
% - worst case is running locally. guaranteed to work.


%%% Local Variables:
%%% mode: latex
%%% TeX-command-extra-options: "-shell-escape"
%%% TeX-master: "../thesis"
%%% End:
