% experiment is different from conclusions

\chapter[]{Anomaly Detection with Recurrent Neural Networks}


for detailed overall trning: 'How large should the batch size be for stochastic gradient descent?'


'advances in optimizing recurrent nn' enhanced sgd still competitive or better
'Equilibrated adaptive learning rates for non-convex optimization' -rmsprop is good. sgd good but issue is just how to adjust weights.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
